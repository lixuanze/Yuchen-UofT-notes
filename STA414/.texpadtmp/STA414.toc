\babel@toc {english}{}
\contentsline {section}{\numberline {1}Introduction}{3}{section.1}% 
\contentsline {section}{\numberline {2}Introduction to Probabilistic Models}{3}{section.2}% 
\contentsline {subsection}{\numberline {2.1}Overview of probabilistic models}{3}{subsection.2.1}% 
\contentsline {paragraph}{Regression}{3}{section*.2}% 
\contentsline {paragraph}{Classification / Clustering}{3}{section*.3}% 
\contentsline {paragraph}{Latent/hidden Variables}{3}{section*.4}% 
\contentsline {paragraph}{Operations on Probabilistic Models}{3}{section*.5}% 
\contentsline {paragraph}{Goals of joint distributions}{4}{section*.6}% 
\contentsline {paragraph}{Joint Dimensionality}{4}{section*.7}% 
\contentsline {subsection}{\numberline {2.2}Sufficient statistics}{4}{subsection.2.2}% 
\contentsline {section}{\numberline {3}Directed Graphical Models}{6}{section.3}% 
\contentsline {subsection}{\numberline {3.1}Decision Theory}{6}{subsection.3.1}% 
\contentsline {subsection}{\numberline {3.2}Joint Distributions}{6}{subsection.3.2}% 
\contentsline {subsubsection}{\numberline {3.2.1}Number of parameters in a joint distribution}{7}{subsubsection.3.2.1}% 
\contentsline {subsubsection}{\numberline {3.2.2}Conditional Independence}{7}{subsubsection.3.2.2}% 
\contentsline {subsection}{\numberline {3.3}Directed acyclic graphical models (DAGM)}{7}{subsection.3.3}% 
\contentsline {paragraph}{Graphical models}{7}{section*.8}% 
\contentsline {paragraph}{Grouping variables}{8}{section*.9}% 
\contentsline {subsubsection}{\numberline {3.3.1}Conditional Independence in DAGM}{8}{subsubsection.3.3.1}% 
\contentsline {subsubsection}{\numberline {3.3.2}Example of a DAGM: Markov Chain}{11}{subsubsection.3.3.2}% 
\contentsline {subsubsection}{\numberline {3.3.3}Plates}{11}{subsubsection.3.3.3}% 
\contentsline {subsubsection}{\numberline {3.3.4}Unobserved Variables}{12}{subsubsection.3.3.4}% 
\contentsline {paragraph}{Partially unobserved variables}{12}{section*.10}% 
\contentsline {paragraph}{Latent variables}{12}{section*.11}% 
\contentsline {paragraph}{Mixture models}{12}{section*.12}% 
\contentsline {paragraph}{Hidden Markov Models (HMMs)}{13}{section*.13}% 
\contentsline {section}{\numberline {4}Exact Inference}{13}{section.4}% 
\contentsline {subsection}{\numberline {4.1}Inference as Conditional Distribution}{13}{subsection.4.1}% 
\contentsline {subsection}{\numberline {4.2}Variable elimination}{13}{subsection.4.2}% 
\contentsline {paragraph}{Simple Example: Chain}{14}{section*.14}% 
\contentsline {subsubsection}{\numberline {4.2.1}Sum-Product Inference}{14}{subsubsection.4.2.1}% 
\contentsline {paragraph}{Directed models}{15}{section*.17}% 
\contentsline {paragraph}{Undirected models}{15}{section*.19}% 
\contentsline {section}{\numberline {5}Message passing, Hidden Markov Models, and Sampling}{16}{section.5}% 
\contentsline {paragraph}{Inference in Trees}{16}{section*.20}% 
\contentsline {subsection}{\numberline {5.1}Message Passing \& Belief Propagation}{17}{subsection.5.1}% 
\contentsline {paragraph}{Joint distribution for undirected graph models}{17}{section*.21}% 
\contentsline {paragraph}{Message-passing}{17}{section*.22}% 
\contentsline {subsection}{\numberline {5.2}Hidden Markov models}{17}{subsection.5.2}% 
\contentsline {subsubsection}{\numberline {5.2.1}Sequential data}{17}{subsubsection.5.2.1}% 
\contentsline {paragraph}{First order Markov chain}{17}{section*.23}% 
\contentsline {paragraph}{Higher-order Markov chains}{18}{section*.24}% 
\contentsline {paragraph}{Parameterization}{18}{section*.25}% 
\contentsline {subsubsection}{\numberline {5.2.2}Hidden Markov Models}{18}{subsubsection.5.2.2}% 
\contentsline {subsubsection}{\numberline {5.2.3}Inference in HMMs}{19}{subsubsection.5.2.3}% 
\contentsline {paragraph}{Main tasks we perform with HMMs}{19}{section*.26}% 
\contentsline {paragraph}{Prediction}{19}{section*.27}% 
\contentsline {paragraph}{Forward Filtering}{20}{section*.28}% 
\contentsline {paragraph}{Backward Filtering}{20}{section*.29}% 
\contentsline {subsection}{\numberline {5.3}Sampling}{20}{subsection.5.3}% 
\contentsline {paragraph}{The problems to be solved}{20}{section*.30}% 
\contentsline {subsubsection}{\numberline {5.3.1}Ancestral Sampling}{21}{subsubsection.5.3.1}% 
\contentsline {paragraph}{Generating marginal samples}{21}{section*.31}% 
\contentsline {paragraph}{Generating conditional samples}{21}{section*.32}% 
\contentsline {section}{\numberline {6}Stochastic Variational Inference}{21}{section.6}% 
\contentsline {subsection}{\numberline {6.1}Motivation}{21}{subsection.6.1}% 
\contentsline {subsection}{\numberline {6.2}the TrueSkill latent variable model}{21}{subsection.6.2}% 
\contentsline {paragraph}{the model}{22}{section*.33}% 
\contentsline {subsection}{\numberline {6.3}Posterior Inference in Latent Variable Models}{22}{subsection.6.3}% 
\contentsline {subsubsection}{\numberline {6.3.1}Approximating the Posterior Inference with Variational Methods}{22}{subsubsection.6.3.1}% 
\contentsline {subsubsection}{\numberline {6.3.2}Kullback-Leibler Divergence}{23}{subsubsection.6.3.2}% 
\contentsline {paragraph}{Variational Objective}{23}{section*.34}% 
\contentsline {paragraph}{Evidence Lower Bound (ELBO)}{23}{section*.35}% 
\contentsline {paragraph}{Optimizing the ELBO}{24}{section*.37}% 
\contentsline {paragraph}{Pathwise Gradient}{24}{section*.38}% 
\contentsline {subsection}{\numberline {6.4}Tutorial - Alternative forms of the ELBO}{25}{subsection.6.4}% 
\contentsline {paragraph}{Form 1}{25}{section*.39}% 
\contentsline {paragraph}{Form 2}{25}{section*.40}% 
\contentsline {paragraph}{Form 3}{25}{section*.41}% 
\contentsline {subsection}{\numberline {6.5}Tutorial - Mean Field Variational Inference}{26}{subsection.6.5}% 
\contentsline {section}{\numberline {7}Sampling and Monte Carlo Methods}{26}{section.7}% 
\contentsline {subsection}{\numberline {7.1}Sampling}{26}{subsection.7.1}% 
\contentsline {paragraph}{Problems to be solved}{26}{section*.43}% 
\contentsline {subsection}{\numberline {7.2}Importance Sampling}{27}{subsection.7.2}% 
\contentsline {subsection}{\numberline {7.3}Rejection Sampling}{29}{subsection.7.3}% 
\contentsline {paragraph}{Rejection sampling in high dimensions}{30}{section*.46}% 
\contentsline {subsection}{\numberline {7.4}Markov Chain Monte Carlo (MCMC)}{30}{subsection.7.4}% 
\contentsline {subsubsection}{\numberline {7.4.1}Metropolis-Hastings method}{30}{subsubsection.7.4.1}% 
\contentsline {section}{\numberline {8}Amortized Inference and Variational Auto-Encoders}{31}{section.8}% 
\contentsline {subsection}{\numberline {8.1}the algorithm for amortized inference}{32}{subsection.8.1}% 
\contentsline {subsection}{\numberline {8.2}Optimizing model parameters}{32}{subsection.8.2}% 
\contentsline {subsection}{\numberline {8.3}Variational Autoencoder (VAE)}{32}{subsection.8.3}% 
\contentsline {paragraph}{Deterministic Autoencoders}{33}{section*.49}% 
\contentsline {paragraph}{Problem 1 - Proximity in data space does not mean proximity in feature space}{34}{section*.50}% 
\contentsline {paragraph}{Problem 2: ``White" latent space region}{34}{section*.51}% 
\contentsline {paragraph}{Solution - Variational Autoencoders (VAEs)}{34}{section*.52}% 
\contentsline {section}{\numberline {9}Normalizing Flows}{34}{section.9}% 
\contentsline {paragraph}{Applications}{34}{section*.53}% 
\contentsline {subsection}{\numberline {9.1}Basics}{35}{subsection.9.1}% 
\contentsline {paragraph}{Constructing flows}{35}{section*.54}% 
\contentsline {subsubsection}{\numberline {9.1.1}More formal construction}{36}{subsubsection.9.1.1}% 
\contentsline {subsection}{\numberline {9.2}Applications}{36}{subsection.9.2}% 
\contentsline {subsubsection}{\numberline {9.2.1}Density estimation and sampling}{36}{subsubsection.9.2.1}% 
\contentsline {subsection}{\numberline {9.3}Methods}{36}{subsection.9.3}% 
\contentsline {subsubsection}{\numberline {9.3.1}Elementwise bijections}{37}{subsubsection.9.3.1}% 
\contentsline {paragraph}{Problem}{37}{section*.55}% 
\contentsline {subsubsection}{\numberline {9.3.2}Linear Flows}{37}{subsubsection.9.3.2}% 
\contentsline {paragraph}{Problem}{37}{section*.56}% 
\contentsline {paragraph}{Computing the determinant}{37}{section*.57}% 
\contentsline {paragraph}{Diagonal}{37}{section*.58}% 
\contentsline {paragraph}{Triangular}{38}{section*.59}% 
\contentsline {paragraph}{Permutation and Orthogonal}{38}{section*.60}% 
\contentsline {paragraph}{Factorizations}{38}{section*.61}% 
\contentsline {paragraph}{Convolution}{38}{section*.62}% 
\contentsline {subsubsection}{\numberline {9.3.3}Planar and Radial Flows}{38}{subsubsection.9.3.3}% 
\contentsline {paragraph}{Planar flows}{38}{section*.63}% 
\contentsline {paragraph}{Sylvester flows}{39}{section*.64}% 
\contentsline {paragraph}{Radial flows}{39}{section*.65}% 
\contentsline {subsubsection}{\numberline {9.3.4}Coupling Flows}{39}{subsubsection.9.3.4}% 
\contentsline {paragraph}{Coupling flows}{39}{section*.66}% 
\contentsline {subsubsection}{\numberline {9.3.5}Autoregressive Flows}{40}{subsubsection.9.3.5}% 
\contentsline {paragraph}{Direct autoregressive flows}{40}{section*.67}% 
\contentsline {paragraph}{Inverse autoregressive flows (IAF)}{40}{section*.68}% 
\contentsline {subsubsection}{\numberline {9.3.6}Residual Flows}{41}{subsubsection.9.3.6}% 
\contentsline {subsubsection}{\numberline {9.3.7}Infinitesimal(Continuous) Flows}{41}{subsubsection.9.3.7}% 

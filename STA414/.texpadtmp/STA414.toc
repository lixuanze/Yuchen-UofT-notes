\babel@toc {english}{}
\contentsline {section}{\numberline {1}Introduction}{3}{section.1}% 
\contentsline {section}{\numberline {2}Introduction to Probabilistic Models}{3}{section.2}% 
\contentsline {subsection}{\numberline {2.1}Overview of probabilistic models}{3}{subsection.2.1}% 
\contentsline {paragraph}{Regression}{3}{section*.2}% 
\contentsline {paragraph}{Classification / Clustering}{3}{section*.3}% 
\contentsline {paragraph}{Latent/hidden Variables}{3}{section*.4}% 
\contentsline {paragraph}{Operations on Probabilistic Models}{3}{section*.5}% 
\contentsline {paragraph}{Goals of joint distributions}{4}{section*.6}% 
\contentsline {paragraph}{Joint Dimensionality}{4}{section*.7}% 
\contentsline {subsection}{\numberline {2.2}Sufficient statistics}{4}{subsection.2.2}% 
\contentsline {section}{\numberline {3}Directed Graphical Models}{6}{section.3}% 
\contentsline {subsection}{\numberline {3.1}Decision Theory}{6}{subsection.3.1}% 
\contentsline {subsection}{\numberline {3.2}Joint Distributions}{6}{subsection.3.2}% 
\contentsline {subsubsection}{\numberline {3.2.1}Number of parameters in a joint distribution}{7}{subsubsection.3.2.1}% 
\contentsline {subsubsection}{\numberline {3.2.2}Conditional Independence}{7}{subsubsection.3.2.2}% 
\contentsline {subsection}{\numberline {3.3}Directed acyclic graphical models (DAGM)}{7}{subsection.3.3}% 
\contentsline {paragraph}{Graphical models}{7}{section*.8}% 
\contentsline {paragraph}{Grouping variables}{8}{section*.9}% 
\contentsline {subsubsection}{\numberline {3.3.1}Conditional Independence in DAGM}{8}{subsubsection.3.3.1}% 
\contentsline {subsubsection}{\numberline {3.3.2}Example of a DAGM: Markov Chain}{11}{subsubsection.3.3.2}% 
\contentsline {subsubsection}{\numberline {3.3.3}Plates}{11}{subsubsection.3.3.3}% 
\contentsline {subsubsection}{\numberline {3.3.4}Unobserved Variables}{12}{subsubsection.3.3.4}% 
\contentsline {paragraph}{Partially unobserved variables}{12}{section*.10}% 
\contentsline {paragraph}{Latent variables}{12}{section*.11}% 
\contentsline {paragraph}{Mixture models}{12}{section*.12}% 
\contentsline {paragraph}{Hidden Markov Models (HMMs)}{13}{section*.13}% 
\contentsline {section}{\numberline {4}Exact Inference}{13}{section.4}% 
\contentsline {subsection}{\numberline {4.1}Inference as Conditional Distribution}{13}{subsection.4.1}% 
\contentsline {subsection}{\numberline {4.2}Variable elimination}{13}{subsection.4.2}% 
\contentsline {paragraph}{Simple Example: Chain}{14}{section*.14}% 
\contentsline {subsubsection}{\numberline {4.2.1}Sum-Product Inference}{14}{subsubsection.4.2.1}% 
\contentsline {paragraph}{Directed models}{15}{section*.17}% 
\contentsline {paragraph}{Undirected models}{15}{section*.19}% 
\contentsline {section}{\numberline {5}Message passing, Hidden Markov Models, and Sampling}{16}{section.5}% 
\contentsline {paragraph}{Inference in Trees}{16}{section*.20}% 
\contentsline {subsection}{\numberline {5.1}Message Passing \& Belief Propagation}{17}{subsection.5.1}% 
\contentsline {paragraph}{Joint distribution for undirected graph models}{17}{section*.21}% 
\contentsline {paragraph}{Message-passing}{17}{section*.22}% 
\contentsline {subsection}{\numberline {5.2}Hidden Markov models}{17}{subsection.5.2}% 
\contentsline {subsubsection}{\numberline {5.2.1}Sequential data}{17}{subsubsection.5.2.1}% 
\contentsline {paragraph}{First order Markov chain}{17}{section*.23}% 
\contentsline {paragraph}{Higher-order Markov chains}{18}{section*.24}% 
\contentsline {paragraph}{Parameterization}{18}{section*.25}% 
\contentsline {subsubsection}{\numberline {5.2.2}Hidden Markov Models}{18}{subsubsection.5.2.2}% 
\contentsline {subsubsection}{\numberline {5.2.3}Inference in HMMs}{19}{subsubsection.5.2.3}% 
\contentsline {paragraph}{Main tasks we perform with HMMs}{19}{section*.26}% 
\contentsline {paragraph}{Prediction}{19}{section*.27}% 
\contentsline {paragraph}{Forward Filtering}{20}{section*.28}% 
\contentsline {paragraph}{Backward Filtering}{20}{section*.29}% 
\contentsline {subsection}{\numberline {5.3}Sampling}{20}{subsection.5.3}% 
\contentsline {paragraph}{The problems to be solved}{20}{section*.30}% 
\contentsline {subsubsection}{\numberline {5.3.1}Ancestral Sampling}{21}{subsubsection.5.3.1}% 
\contentsline {paragraph}{Generating marginal samples}{21}{section*.31}% 
\contentsline {paragraph}{Generating conditional samples}{21}{section*.32}% 
\contentsline {section}{\numberline {6}Stochastic Variational Inference}{21}{section.6}% 
\contentsline {subsection}{\numberline {6.1}the TrueSkill latent variable model}{21}{subsection.6.1}% 
\contentsline {paragraph}{the model}{21}{section*.33}% 
\contentsline {subsection}{\numberline {6.2}Posterior Inference in Latent Variable Models}{22}{subsection.6.2}% 
\contentsline {subsubsection}{\numberline {6.2.1}Approximating the Posterior Inference with Variational Methods}{22}{subsubsection.6.2.1}% 
\contentsline {subsubsection}{\numberline {6.2.2}Kullback-Leibler Divergence}{22}{subsubsection.6.2.2}% 
\contentsline {paragraph}{Variational Objective}{23}{section*.35}% 
\contentsline {paragraph}{Evidence Lower Bound (ELBO)}{23}{section*.36}% 
\contentsline {paragraph}{Optimizing the ELBO}{24}{section*.37}% 
\contentsline {paragraph}{Pathwise Gradient}{24}{section*.38}% 
\contentsline {section}{\numberline {7}Sampling and Monte Carlo Methods}{24}{section.7}% 
\contentsline {subsection}{\numberline {7.1}Sampling}{24}{subsection.7.1}% 
\contentsline {paragraph}{Problems to be solved}{25}{section*.39}% 
\contentsline {subsection}{\numberline {7.2}Importance Sampling}{26}{subsection.7.2}% 
\contentsline {subsection}{\numberline {7.3}Rejection Sampling}{27}{subsection.7.3}% 
\contentsline {subsection}{\numberline {7.4}Metropolis-Hastings method}{27}{subsection.7.4}% 
